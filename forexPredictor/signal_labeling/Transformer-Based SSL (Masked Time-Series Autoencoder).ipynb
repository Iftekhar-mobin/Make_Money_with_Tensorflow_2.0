{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f75a651e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LayerNormalization, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import MultiHeadAttention, LayerNormalization, Add\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9001730b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ File found: D:\\Repos_git\\Make_Money_with_Tensorflow_2.0\\forexPredictor\\ohlc_data\\0_61938.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.20997</td>\n",
       "      <td>1.21089</td>\n",
       "      <td>1.20966</td>\n",
       "      <td>1.20999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.20481</td>\n",
       "      <td>1.20569</td>\n",
       "      <td>1.20479</td>\n",
       "      <td>1.20538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.20537</td>\n",
       "      <td>1.20574</td>\n",
       "      <td>1.20341</td>\n",
       "      <td>1.20553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.20556</td>\n",
       "      <td>1.20689</td>\n",
       "      <td>1.20442</td>\n",
       "      <td>1.20469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.20468</td>\n",
       "      <td>1.20599</td>\n",
       "      <td>1.20380</td>\n",
       "      <td>1.20573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Open     High      Low    Close\n",
       "0  1.20997  1.21089  1.20966  1.20999\n",
       "1  1.20481  1.20569  1.20479  1.20538\n",
       "2  1.20537  1.20574  1.20341  1.20553\n",
       "3  1.20556  1.20689  1.20442  1.20469\n",
       "4  1.20468  1.20599  1.20380  1.20573"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_num = 5\n",
    "sequence_length = 8  # Number of time steps to consider\n",
    "\n",
    "# Define file and directory names\n",
    "file_name = '0_61938.csv'\n",
    "data_dir = 'ohlc_data'\n",
    "# parent_dir = 'forexPredictor'\n",
    "# repo = 'Repos_git'\n",
    "# repo_dir = 'Make_Money_with_Tensorflow_2.0'\n",
    "# Get the absolute base directory dynamically\n",
    "base_dir = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Move up one level\n",
    "\n",
    "# Construct the full file path in an OS-independent way\n",
    "# data_path = os.path.join(base_dir, repo, repo_dir, parent_dir, data_dir, file_name)\n",
    "data_path = os.path.join(base_dir, data_dir, file_name)\n",
    "\n",
    "# Check if the file exists before using it\n",
    "if os.path.exists(data_path):\n",
    "    print(f\"✅ File found: {data_path}\")\n",
    "else:\n",
    "    print(f\"❌ Error: File not found at {data_path}\")\n",
    "\n",
    "\n",
    "ucols=['Open', 'High', 'Low', 'Close']\n",
    "data_main = pd.read_csv(data_path, usecols=ucols)\n",
    "data_main.reset_index(drop=True, inplace=True)\n",
    "data_main.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1f0237",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data_main.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5345d02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)        [(None, 10, 4)]              0         []                            \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, 10, 4)                308       ['input_2[0][0]',             \n",
      " ltiHeadAttention)                                                   'input_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, 10, 4)                0         ['multi_head_attention_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_4 (Add)                 (None, 10, 4)                0         ['input_2[0][0]',             \n",
      "                                                                     'dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, 10, 4)                8         ['add_4[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, 10, 128)              640       ['layer_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, 10, 4)                516       ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, 10, 4)                0         ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " add_5 (Add)                 (None, 10, 4)                0         ['layer_normalization_4[0][0]'\n",
      "                                                                    , 'dropout_5[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, 10, 4)                8         ['add_5[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, 10, 4)                308       ['layer_normalization_5[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, 10, 4)                0         ['multi_head_attention_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " add_6 (Add)                 (None, 10, 4)                0         ['layer_normalization_5[0][0]'\n",
      "                                                                    , 'dropout_6[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, 10, 4)                8         ['add_6[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, 10, 128)              640       ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, 10, 4)                516       ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, 10, 4)                0         ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " add_7 (Add)                 (None, 10, 4)                0         ['layer_normalization_6[0][0]'\n",
      "                                                                    , 'dropout_7[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, 10, 4)                8         ['add_7[0][0]']               \n",
      " erNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, 10, 4)                20        ['layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2980 (11.64 KB)\n",
      "Trainable params: 2980 (11.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/5\n",
      "1936/1936 [==============================] - 9s 4ms/step - loss: 0.0551\n",
      "Epoch 2/5\n",
      "1936/1936 [==============================] - 7s 4ms/step - loss: 0.0085\n",
      "Epoch 3/5\n",
      "1936/1936 [==============================] - 7s 3ms/step - loss: 0.0031\n",
      "Epoch 4/5\n",
      "1936/1936 [==============================] - 7s 3ms/step - loss: 0.0026\n",
      "Epoch 5/5\n",
      "1936/1936 [==============================] - 7s 3ms/step - loss: 0.0028\n",
      "1936/1936 [==============================] - 3s 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Teacher\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# -----------------------------\n",
    "# Step 1: Load & preprocess OHLC data\n",
    "# -----------------------------\n",
    "# df = pd.read_csv(\"ohlc.csv\")  # Your OHLC dataset (must contain Open, High, Low, Close)\n",
    "\n",
    "# Normalize OHLC\n",
    "scaler = MinMaxScaler()\n",
    "ohlc = scaler.fit_transform(df[[\"Open\", \"High\", \"Low\", \"Close\"]])\n",
    "\n",
    "# Create time series sequences\n",
    "def create_sequences(data, window_size=10):\n",
    "    sequences = []\n",
    "    for i in range(len(data) - window_size):\n",
    "        sequences.append(data[i:i+window_size])\n",
    "    return np.array(sequences)\n",
    "\n",
    "window_size = 10\n",
    "sequences = create_sequences(ohlc, window_size)  # Shape: (num_samples, 10, 4)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 2: Masking function\n",
    "# -----------------------------\n",
    "def mask_time_series(data, mask_ratio=0.15):\n",
    "    mask = np.random.rand(*data.shape) < mask_ratio\n",
    "    masked = data.copy()\n",
    "    masked[mask] = 0  # Masked with 0s (can also use noise)\n",
    "    return masked, mask\n",
    "\n",
    "masked_sequences, mask = mask_time_series(sequences)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 3: Transformer Encoder Block\n",
    "# -----------------------------\n",
    "def transformer_encoder(inputs, num_heads=4, dff=128, dropout_rate=0.1):\n",
    "    # Multi-head attention\n",
    "    attention_output = MultiHeadAttention(num_heads=num_heads, key_dim=inputs.shape[-1])(inputs, inputs)\n",
    "    attention_output = Dropout(dropout_rate)(attention_output)\n",
    "    attention_output = Add()([inputs, attention_output])\n",
    "    attention_output = LayerNormalization()(attention_output)\n",
    "\n",
    "    # Feedforward\n",
    "    ffn_output = Dense(dff, activation=\"relu\")(attention_output)\n",
    "    ffn_output = Dense(inputs.shape[-1])(ffn_output)\n",
    "    ffn_output = Dropout(dropout_rate)(ffn_output)\n",
    "    ffn_output = Add()([attention_output, ffn_output])\n",
    "    return LayerNormalization()(ffn_output)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 4: Transformer Autoencoder\n",
    "# -----------------------------\n",
    "input_layer = Input(shape=(window_size, 4))\n",
    "x = transformer_encoder(input_layer, num_heads=4)\n",
    "x = transformer_encoder(x, num_heads=4)\n",
    "output_layer = Dense(4)(x)  # Predict all 4 OHLC values\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=\"adam\", loss=\"mse\")\n",
    "model.summary()\n",
    "\n",
    "# -----------------------------\n",
    "# Step 5: Train\n",
    "# -----------------------------\n",
    "model.fit(masked_sequences, sequences, epochs=5, batch_size=32)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 6: Extract latent features\n",
    "# -----------------------------\n",
    "encoder = Model(inputs=input_layer, outputs=x)  # Use the second transformer's output as features\n",
    "features = encoder.predict(sequences)  # Shape: (n_samples, 10, 4)\n",
    "\n",
    "# Optional: Pool features (e.g., mean over time steps)\n",
    "pooled_features = np.mean(features, axis=1)  # Shape: (n_samples, 4)\n",
    "\n",
    "# -----------------------------\n",
    "# Step 7: Cluster to get Buy/Sell/Hold\n",
    "# -----------------------------\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "clusters = kmeans.fit_predict(pooled_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb976e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tslearn.clustering import TimeSeriesKMeans\n",
    "\n",
    "# Use the original OHLC sequences (or features)\n",
    "# Shape: (n_samples, time_steps, features)\n",
    "model = TimeSeriesKMeans(n_clusters=3, metric=\"dtw\", random_state=42)\n",
    "clusters = model.fit_predict(pooled_features)  # or use features if more abstract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85780756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize clustering on price\n",
    "df[\"Signal\"] = \"Hold\"  # default\n",
    "df.loc[window_size:, \"Signal\"] = pd.Series(clusters).map({0: \"Buy\", 1: \"Sell\", 2: \"Hold\"}).values\n",
    "\n",
    "\n",
    "# Plot\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df[\"Close\"], label=\"Close Price\", alpha=0.5)\n",
    "\n",
    "buy_idx = df.index[df[\"Signal\"] == \"Buy\"]\n",
    "sell_idx = df.index[df[\"Signal\"] == \"Sell\"]\n",
    "hold_idx = df.index[df[\"Signal\"] == \"Hold\"]\n",
    "\n",
    "plt.scatter(buy_idx, df.loc[buy_idx, \"Close\"], color='green', label=\"Buy\", marker=\"^\")\n",
    "plt.scatter(sell_idx, df.loc[sell_idx, \"Close\"], color='red', label=\"Sell\", marker=\"v\")\n",
    "plt.scatter(hold_idx, df.loc[hold_idx, \"Close\"], color='gray', label=\"Hold\", alpha=0.2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"Stock Price with SSL Clustered Buy/Sell/Hold\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4be519",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_features = tsne.fit_transform(pooled_features)\n",
    "\n",
    "plt.scatter(tsne_features[:, 0], tsne_features[:, 1], c=clusters, cmap='viridis')\n",
    "plt.title(\"Wave-aware clustering of OHLC sequences\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
